{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport pandas as pd\nimport multiprocessing\nimport time\nfrom scipy import io","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-12T19:46:40.382645Z","iopub.execute_input":"2022-07-12T19:46:40.383080Z","iopub.status.idle":"2022-07-12T19:46:40.388959Z","shell.execute_reply.started":"2022-07-12T19:46:40.383046Z","shell.execute_reply":"2022-07-12T19:46:40.387714Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"nrows = 6   # Number of internal corner rows to be found\nncols = 8   # Number of internal corner cols to be found\n\n# Shape of the image\nrows = 6336\ncols = 9054\n\ncriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\np_flags = cv2.CALIB_USE_INTRINSIC_GUESS + cv2.CALIB_RATIONAL_MODEL\nf_flags = cv2.fisheye.CALIB_USE_INTRINSIC_GUESS + cv2.fisheye.CALIB_RECOMPUTE_EXTRINSIC\n\nsquare_size = 25 # mm\ndeformation_vertex = 0. # mm\ncamModel = 1\n\nK_pth = \"\"\nKnew_pth = \"\"\ndist_pth = \"\"\nrvecs_pth = \"\"\ntvecs_pth = \"\"\n\ncorner_pth = \"../input/corner-positions-for-underwater-photos/all_corners_(247 48 2).csv\"\nsave_pth = \"./\"\ncameraIntrinsics = \"\" # Input the numbers manually\nfx = 3168\nfy = 3168\ncx = 4752.5\ncy = 3168.5","metadata":{"execution":{"iopub.status.busy":"2022-07-12T20:45:00.517228Z","iopub.execute_input":"2022-07-12T20:45:00.518280Z","iopub.status.idle":"2022-07-12T20:45:00.527272Z","shell.execute_reply.started":"2022-07-12T20:45:00.518225Z","shell.execute_reply":"2022-07-12T20:45:00.526307Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def initCameraIntrinsics(fx,fy,cx,cy):\n\n    K = np.zeros((3,3),np.float32)\n    K[0,0] = fx\n    K[1,1] = fy\n    K[2,2] = 1\n    K[0,2] = cx\n    K[1,2] = cy\n\n    return K\n\ndef find_reprojection_error(objPoints, imgPoints, K, dist, rvecs, tvecs,cameraModel):\n\n    num_images = objPoints.shape[0]\n    e_points = []\n    overall_mean_error = 0\n\n    for n in range(num_images):\n\n        if cameraModel == 0:\n            reprojected_points,_ = cv2.projectPoints(np.array([objPoints[n,:,:]]), rvecs[n,:,:], tvecs[n,:,:], K, dist)\n        else:\n            reprojected_points,_ = cv2.fisheye.projectPoints(np.array([objPoints[n,:,:]]), rvecs[n,:,:], tvecs[n,:,:], K, dist)\n\n        # Squeeze the imgPoints and reprojected_points to be Nx2\n        error = np.squeeze(reprojected_points) - np.squeeze(imgPoints[n,:,:])\n        e_vec = np.sqrt(np.power(error[:,0],2) + np.power(error[:,1],2)).reshape(-1,1)\n        e_points.append(e_vec)\n\n        overall_mean_error = overall_mean_error + np.mean(e_vec)\n\n    e_points = np.array(e_points)   # Shape should be num_images x N x 1\n\n    overall_mean_error = overall_mean_error/num_images\n\n    return overall_mean_error, e_points\n\ndef get_UndistortedImage(distorted, K, dist, cameraModel, Knew=None, new_size=None):\n\n    if new_size == None:\n        new_size = (distorted.shape[1],distorted.shape[0])\n    # map1,map2 = cv2.fisheye.initUndistortRectifyMap(K,dist,np.eye(3),new_K,(cols,rows),cv2.CV_16SC2)\n    # undistorted = cv2.remap(distorted,map1,map2,cv2.INTER_LINEAR)\n\n    if cameraModel == 0:\n        undistorted = cv2.undistort(distorted, K, dist, newCameraMatrix=Knew)\n    else:\n        if Knew == None:\n            Knew = K\n\n        undistorted = cv2.fisheye.undistortImage(distorted,K,dist,Knew=Knew,new_size=new_size)\n\n    return undistorted\n\ndef generate_objectPoints(nrows,ncols,deformation_vertex,square_size,img_shape):\n\n    \"\"\"\n    nrows: Number of internal corner rows\n    ncols: Number of interal corner columns\n    deformation_vertex: Point of largest deviation\n    square_size: Size of a chessboard square\n    img_shape: Shape of the detected image points\n    \"\"\"\n\n    # Object points are created like (0,0,0), (1,0,0), (2,0,0), ...\n    objPoints = np.zeros((nrows*ncols,3),np.float32)\n    objPoints[:,:2] = np.mgrid[0:nrows,0:ncols].T.reshape(-1,2)\n\n    # Non-planar deformation to be characterized as a parabola\n    # Assume that the square size is 25 mm and deformation is about 2.5 mm at\n    # the location of its largest bump\n\n    # f(y) = a(y-(ncols-1)/2)^2 + max_deformation\n    a = -(deformation_vertex/square_size)/((ncols-1)/2)**2\n    z_vals = a*np.power((np.array(range(ncols)) - (ncols-1)/2),2) + deformation_vertex/square_size\n\n    objPoints[:,2] = np.repeat(z_vals,nrows)\n    objectPoints = np.empty((img_shape[0],img_shape[1],3))\n    objectPoints = np.tile(np.array([objPoints]),(img_shape[0],1,1))\n\n    return objectPoints\n\ndef get_cameraParams(cameraModel,deformation_vertex,save_pth,pinhole_flags,fisheye_flags):\n\n    # Read the corners from the saved CSV file\n    df = pd.read_csv(corner_pth,header=None)\n    imgPoints = df[0].to_numpy()\n\n    imgPoints = imgPoints.reshape(-1,nrows*ncols,2)\n\n    # ----------------------------------------------------------------------------- #\n    # Read the file with the initial camera parameters if available\n\n    if K_pth:\n        df_K = pd.read_csv(K_pth,header=None)\n        K = df_K[0].to_numpy()\n        K = K.reshape((3,3))\n        \n    else:\n        K = initCameraIntrinsics(fx,fy,cx,cy)\n\n    # ----------------------------------------------------------------------------- #\n\n    # Create the non-planar world points\n\n    objectPoints = generate_objectPoints(nrows,ncols,deformation_vertex,square_size,imgPoints.shape)\n\n    # ----------------------------------------------------------------------------- #\n    if cameraModel == 0:\n        # Pinhole calibration\n        ret, K, dist, rvecs, tvecs, sigma_int, sigma_ext, error_per_view = cv2.calibrateCameraExtended(objectPoints.astype(np.float32), imgPoints.astype(np.float32), (cols,rows), K, np.zeros((1,6)), flags=pinhole_flags)\n        new_K, roi = cv2.getOptimalNewCameraMatrix(K, dist, (cols,rows), 1, (cols,rows))\n        \n        np.savetxt(save_pth+\"/def_v_{:.2f}\".format(deformation_vertex)+\"/K_errors.csv\", sigma_int,delimiter=\",\")\n        np.savetxt(save_pth+\"/def_v_{:.2f}\".format(deformation_vertex)+\"/Extrinsic_errors.csv\", sigma_ext,delimiter=\",\")\n        np.savetxt(save_pth+\"/def_v_{:.2f}\".format(deformation_vertex)+\"/Per_View_RMS_errors.csv\", error_per_view,delimiter=\",\")\n    \n    else:\n        # Fisheye calibration\n        objectPoints = np.expand_dims(np.asarray(objectPoints), -2)\n        imgPoints = np.expand_dims(np.asarray(imgPoints), -2)\n        ret, K, dist, rvecs, tvecs = cv2.fisheye.calibrate(objectPoints.astype(np.float64), imgPoints.astype(np.float64), (cols,rows), K, np.zeros((1,4),dtype=np.float64), flags=fisheye_flags)\n        new_K = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(K,dist,(cols,rows),np.eye(3),balance=0,new_size=(cols,rows))\n        \n        print(ret)\n    # ----------------------------------------------------------------------------- #\n\n    np.savetxt(save_pth+\"/def_v_{:.2f}\".format(deformation_vertex)+\"/camIntrinsics_K_{}.csv\".format(K.shape), K.flatten(),delimiter=\",\")\n    np.savetxt(save_pth+\"/def_v_{:.2f}\".format(deformation_vertex)+\"/camIntrinsics_Knew_{}.csv\".format(new_K.shape), new_K.flatten(), delimiter=\",\")\n    np.savetxt(save_pth+\"/def_v_{:.2f}\".format(deformation_vertex)+\"/distortion.csv\", dist.flatten(), delimiter=\",\")\n    np.savetxt(save_pth+\"/def_v_{:.2f}\".format(deformation_vertex)+\"/rvecs_{}.csv\".format(np.array(rvecs).shape), np.array(rvecs).flatten(),delimiter=\",\")\n    np.savetxt(save_pth+\"/def_v_{:.2f}\".format(deformation_vertex)+\"/tvecs_{}.csv\".format(np.array(tvecs).shape), np.array(tvecs).flatten(),delimiter=\",\")\n\n    return True\n\ndef get_Reprojection_error(cameraModel):\n\n    if K_pth:\n        df_K = pd.read_csv(K_pth,header=None)\n        K = df_K[0].to_numpy()\n        K = K.reshape((3,3))\n\n    if Knew_pth:\n        df_Knew = pd.read_csv(Knew_pth,header=None)\n        Knew = df_Knew[0].to_numpy()\n        Knew = Knew.reshape((3,3))\n\n    if dist_pth:\n        df_dist = pd.read_csv(dist_pth,header=None)\n        dist = df_dist[0].to_numpy()\n\n    if rvecs_pth:\n        df_rvecs = pd.read_csv(rvecs_pth,header=None)\n        rvecs = df_rvecs[0].to_numpy()\n        rvecs = rvecs.reshape((-1,3,1)).astype(np.float64)\n\n    if tvecs_pth:\n        df_tvecs = pd.read_csv(tvecs_pth,header=None)\n        tvecs = df_tvecs[0].to_numpy()\n        tvecs = tvecs.reshape((-1,3,1)).astype(np.float64)\n\n    df = pd.read_csv(corner_pth,header=None)\n    imgPoints = df[0].to_numpy()\n    imgPoints = imgPoints.reshape(-1,nrows*ncols,2)\n\n    objectPoints = generate_objectPoints(nrows,ncols,deformation_vertex,square_size,imgPoints.shape)\n\n    mean_error, error_points = find_reprojection_error(objPoints, imgPoints, K, dist, rvecs, tvecs, cameraModel)\n\n    return mean_error, error_points\n","metadata":{"execution":{"iopub.status.busy":"2022-07-12T20:45:05.724119Z","iopub.execute_input":"2022-07-12T20:45:05.724527Z","iopub.status.idle":"2022-07-12T20:45:05.771108Z","shell.execute_reply.started":"2022-07-12T20:45:05.724491Z","shell.execute_reply":"2022-07-12T20:45:05.769993Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"os.makedirs(save_pth+\"temp3\")\n# os.chdir(\"/kaggle/working/temp\")\n!pwd","metadata":{"execution":{"iopub.status.busy":"2022-07-12T20:45:25.942187Z","iopub.execute_input":"2022-07-12T20:45:25.942576Z","iopub.status.idle":"2022-07-12T20:45:26.711169Z","shell.execute_reply.started":"2022-07-12T20:45:25.942543Z","shell.execute_reply":"2022-07-12T20:45:26.709449Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"save_pth = \"/kaggle/working/temp3\"\nvertices = (np.linspace(-1,1,11))\nfor i in vertices:\n    print(\"Vertex \", i)\n    if not os.path.isdir(save_pth + \"/def_v_{:.2f}\".format(i)):\n        os.makedirs(save_pth + \"/def_v_{:.2f}\".format(i))\n    get_cameraParams(camModel,i,save_pth,p_flags,f_flags)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T20:45:47.954619Z","iopub.execute_input":"2022-07-12T20:45:47.955047Z","iopub.status.idle":"2022-07-12T20:46:50.000155Z","shell.execute_reply.started":"2022-07-12T20:45:47.955009Z","shell.execute_reply":"2022-07-12T20:46:49.999203Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Vertex  -1.0\n2.7617574134435414\nVertex  -0.8\n2.7332079770483273\nVertex  -0.6\n2.7151191522277047\nVertex  -0.3999999999999999\n2.707760543898034\nVertex  -0.19999999999999996\n2.7112565591338607\nVertex  0.0\n2.725603581880236\nVertex  0.20000000000000018\n2.750671330267563\nVertex  0.40000000000000013\n2.786211440986644\nVertex  0.6000000000000001\n2.831871960866236\nVertex  0.8\n2.887216106760425\nVertex  1.0\n2.951743257114643\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r all_params2.zip /kaggle/working/temp2","metadata":{"execution":{"iopub.status.busy":"2022-07-12T20:27:46.202824Z","iopub.execute_input":"2022-07-12T20:27:46.203925Z","iopub.status.idle":"2022-07-12T20:27:47.031117Z","shell.execute_reply.started":"2022-07-12T20:27:46.203870Z","shell.execute_reply":"2022-07-12T20:27:47.029836Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/temp2/ (stored 0%)\n  adding: kaggle/working/temp2/def_v_1.00/ (stored 0%)\n  adding: kaggle/working/temp2/def_v_1.00/rvecs_(247, 3, 1).csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_1.00/Extrinsic_errors.csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_1.00/K_errors.csv (deflated 61%)\n  adding: kaggle/working/temp2/def_v_1.00/distortion.csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_1.00/tvecs_(247, 3, 1).csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_1.00/camIntrinsics_K_(3, 3).csv (deflated 63%)\n  adding: kaggle/working/temp2/def_v_1.00/Per_View_RMS_errors.csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_1.00/camIntrinsics_Knew_(3, 3).csv (deflated 63%)\n  adding: kaggle/working/temp2/def_v_0.40/ (stored 0%)\n  adding: kaggle/working/temp2/def_v_0.40/rvecs_(247, 3, 1).csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_0.40/Extrinsic_errors.csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_0.40/K_errors.csv (deflated 62%)\n  adding: kaggle/working/temp2/def_v_0.40/distortion.csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_0.40/tvecs_(247, 3, 1).csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_0.40/camIntrinsics_K_(3, 3).csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_0.40/Per_View_RMS_errors.csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_0.40/camIntrinsics_Knew_(3, 3).csv (deflated 63%)\n  adding: kaggle/working/temp2/def_v_-1.00/ (stored 0%)\n  adding: kaggle/working/temp2/def_v_-1.00/rvecs_(247, 3, 1).csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_-1.00/Extrinsic_errors.csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_-1.00/K_errors.csv (deflated 62%)\n  adding: kaggle/working/temp2/def_v_-1.00/distortion.csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_-1.00/tvecs_(247, 3, 1).csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_-1.00/camIntrinsics_K_(3, 3).csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_-1.00/Per_View_RMS_errors.csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_-1.00/camIntrinsics_Knew_(3, 3).csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_-0.40/ (stored 0%)\n  adding: kaggle/working/temp2/def_v_-0.40/rvecs_(247, 3, 1).csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_-0.40/Extrinsic_errors.csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_-0.40/K_errors.csv (deflated 61%)\n  adding: kaggle/working/temp2/def_v_-0.40/distortion.csv (deflated 63%)\n  adding: kaggle/working/temp2/def_v_-0.40/tvecs_(247, 3, 1).csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_-0.40/camIntrinsics_K_(3, 3).csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_-0.40/Per_View_RMS_errors.csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_-0.40/camIntrinsics_Knew_(3, 3).csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_0.20/ (stored 0%)\n  adding: kaggle/working/temp2/def_v_0.20/rvecs_(247, 3, 1).csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_0.20/Extrinsic_errors.csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_0.20/K_errors.csv (deflated 61%)\n  adding: kaggle/working/temp2/def_v_0.20/distortion.csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_0.20/tvecs_(247, 3, 1).csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_0.20/camIntrinsics_K_(3, 3).csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_0.20/Per_View_RMS_errors.csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_0.20/camIntrinsics_Knew_(3, 3).csv (deflated 63%)\n  adding: kaggle/working/temp2/def_v_0.80/ (stored 0%)\n  adding: kaggle/working/temp2/def_v_0.80/rvecs_(247, 3, 1).csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_0.80/Extrinsic_errors.csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_0.80/K_errors.csv (deflated 63%)\n  adding: kaggle/working/temp2/def_v_0.80/distortion.csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_0.80/tvecs_(247, 3, 1).csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_0.80/camIntrinsics_K_(3, 3).csv (deflated 63%)\n  adding: kaggle/working/temp2/def_v_0.80/Per_View_RMS_errors.csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_0.80/camIntrinsics_Knew_(3, 3).csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_-0.80/ (stored 0%)\n  adding: kaggle/working/temp2/def_v_-0.80/rvecs_(247, 3, 1).csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_-0.80/Extrinsic_errors.csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_-0.80/K_errors.csv (deflated 61%)\n  adding: kaggle/working/temp2/def_v_-0.80/distortion.csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_-0.80/tvecs_(247, 3, 1).csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_-0.80/camIntrinsics_K_(3, 3).csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_-0.80/Per_View_RMS_errors.csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_-0.80/camIntrinsics_Knew_(3, 3).csv (deflated 65%)\n  adding: kaggle/working/temp2/def_v_0.00/ (stored 0%)\n  adding: kaggle/working/temp2/def_v_0.00/rvecs_(247, 3, 1).csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_0.00/Extrinsic_errors.csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_0.00/K_errors.csv (deflated 62%)\n  adding: kaggle/working/temp2/def_v_0.00/distortion.csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_0.00/tvecs_(247, 3, 1).csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_0.00/camIntrinsics_K_(3, 3).csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_0.00/Per_View_RMS_errors.csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_0.00/camIntrinsics_Knew_(3, 3).csv (deflated 65%)\n  adding: kaggle/working/temp2/def_v_-0.20/ (stored 0%)\n  adding: kaggle/working/temp2/def_v_-0.20/rvecs_(247, 3, 1).csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_-0.20/Extrinsic_errors.csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_-0.20/K_errors.csv (deflated 61%)\n  adding: kaggle/working/temp2/def_v_-0.20/distortion.csv (deflated 63%)\n  adding: kaggle/working/temp2/def_v_-0.20/tvecs_(247, 3, 1).csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_-0.20/camIntrinsics_K_(3, 3).csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_-0.20/Per_View_RMS_errors.csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_-0.20/camIntrinsics_Knew_(3, 3).csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_0.60/ (stored 0%)\n  adding: kaggle/working/temp2/def_v_0.60/rvecs_(247, 3, 1).csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_0.60/Extrinsic_errors.csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_0.60/K_errors.csv (deflated 63%)\n  adding: kaggle/working/temp2/def_v_0.60/distortion.csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_0.60/tvecs_(247, 3, 1).csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_0.60/camIntrinsics_K_(3, 3).csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_0.60/Per_View_RMS_errors.csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_0.60/camIntrinsics_Knew_(3, 3).csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_-0.60/ (stored 0%)\n  adding: kaggle/working/temp2/def_v_-0.60/rvecs_(247, 3, 1).csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_-0.60/Extrinsic_errors.csv (deflated 55%)\n  adding: kaggle/working/temp2/def_v_-0.60/K_errors.csv (deflated 61%)\n  adding: kaggle/working/temp2/def_v_-0.60/distortion.csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_-0.60/tvecs_(247, 3, 1).csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_-0.60/camIntrinsics_K_(3, 3).csv (deflated 64%)\n  adding: kaggle/working/temp2/def_v_-0.60/Per_View_RMS_errors.csv (deflated 54%)\n  adding: kaggle/working/temp2/def_v_-0.60/camIntrinsics_Knew_(3, 3).csv (deflated 65%)\n","output_type":"stream"}]},{"cell_type":"code","source":"mean_error, error_point = get_Reprojection_error(camModel)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(tvecs)\n# print(np.array(tvecs)[0,:,:])\n# print(np.array(rvecs).flatten())\n# np.savetxt(\"./rvecs.csv\", np.array(rvecs).flatten(), delimiter=\",\")","metadata":{"execution":{"iopub.status.busy":"2022-07-08T18:08:15.805267Z","iopub.execute_input":"2022-07-08T18:08:15.805852Z","iopub.status.idle":"2022-07-08T18:08:15.814308Z","shell.execute_reply.started":"2022-07-08T18:08:15.805805Z","shell.execute_reply":"2022-07-08T18:08:15.812725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_K = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(K,dist,(cols,rows),np.eye(3),balance=0,new_size=(cols,rows))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T18:08:15.816099Z","iopub.execute_input":"2022-07-08T18:08:15.819767Z","iopub.status.idle":"2022-07-08T18:08:15.826117Z","shell.execute_reply.started":"2022-07-08T18:08:15.819718Z","shell.execute_reply":"2022-07-08T18:08:15.825337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(K)\nprint(new_K)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T18:08:15.829079Z","iopub.execute_input":"2022-07-08T18:08:15.829878Z","iopub.status.idle":"2022-07-08T18:08:15.839389Z","shell.execute_reply.started":"2022-07-08T18:08:15.829835Z","shell.execute_reply":"2022-07-08T18:08:15.83792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"distorted = cv2.imread(\"../input/underwater-photos/Underwater/Pool Calibration Photos - June 29/Pool_0.JPG\")\n\n# map1,map2 = cv2.fisheye.initUndistortRectifyMap(K,dist,np.eye(3),new_K,(cols,rows),cv2.CV_16SC2) \n# undistorted = cv2.remap(distorted,map1,map2,cv2.INTER_LINEAR)\n\nundistorted = cv2.fisheye.undistortImage(distorted,K,dist,Knew=new_K,new_size=(cols,rows))\n\n%matplotlib inline\nplt.imshow(cv2.cvtColor(undistorted,cv2.COLOR_BGR2RGB))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T18:08:15.841117Z","iopub.execute_input":"2022-07-08T18:08:15.841746Z","iopub.status.idle":"2022-07-08T18:08:24.686141Z","shell.execute_reply.started":"2022-07-08T18:08:15.84168Z","shell.execute_reply":"2022-07-08T18:08:24.684941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ret","metadata":{"execution":{"iopub.status.busy":"2022-07-08T18:08:24.687776Z","iopub.execute_input":"2022-07-08T18:08:24.688136Z","iopub.status.idle":"2022-07-08T18:08:24.69531Z","shell.execute_reply.started":"2022-07-08T18:08:24.688104Z","shell.execute_reply":"2022-07-08T18:08:24.693986Z"},"trusted":true},"execution_count":null,"outputs":[]}]}